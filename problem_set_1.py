# -*- coding: utf-8 -*-
"""backup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hrPlQs9ixYSOrjuctbT9mEOX5mHXfsF_
"""

!pip install mlflow

!pip install kaggle

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d duttadebadri/image-classification

!unzip -q image-classification.zip -d image-classification

import os
import mlflow

mlflow_dir = "/content/drive/MyDrive/mlflow_fraud"
os.makedirs(mlflow_dir, exist_ok=True)

mlflow.set_tracking_uri(f"sqlite:///{mlflow_dir}/mlflow.db")
mlflow.set_experiment("image-classification-experiment")



from google.colab import drive
drive.mount('/content/drive')

"""# Prepare MLFlow"""

import os
import mlflow

mlflow_dir = "/content/drive/MyDrive/mlflow_image_classification"
os.makedirs(mlflow_dir, exist_ok=True)

mlflow.set_tracking_uri(f"file://{mlflow_dir}")
mlflow.set_experiment("image-classification-experiment")

"""# Loading Data and Splitting data"""

import tensorflow as tf

batch_size = 2
img_height = 224
img_width = 224

train_path ="image-classification/images/images"
train_dir = pathlib.Path(train_path).with_suffix('')



train_ds = tf.keras.utils.image_dataset_from_directory(
  train_dir,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_path ="image-classification/validation/validation"
val_dir = pathlib.Path(val_path).with_suffix('')

val_ds = tf.keras.utils.image_dataset_from_directory(
  val_dir,
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_name = train_ds.class_names
print(class_name)

image_batch, label_batch = next(iter(train_ds))

import matplotlib.pyplot as plt


plt.figure(figsize=(10, 10))
for i in range(min(9, len(image_batch))):  # Ensure we don't exceed batch size
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(image_batch[i].numpy().astype("uint8"))  # Convert tensor to uint8
    plt.title(class_name[label_batch[i].numpy()])  # Get class name
    plt.axis("off")
plt.show()

for image_batch, labels_batch in train_ds:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

"""# Preprocessing Image data"""

normalization_layer = tf.keras.layers.Rescaling(1./255)

import numpy as np

normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
image_batch, labels_batch = next(iter(normalized_ds))
first_image = image_batch[0]
# Notice the pixel values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

"""# Model Architecture"""

num_classes = len(class_name)
print(num_classes)

model = tf.keras.Sequential([
  tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),
  tf.keras.layers.Conv2D(16, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(16, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Conv2D(32, 3, activation='relu'),
  tf.keras.layers.MaxPooling2D(),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dense(num_classes, activation='softmax')
]
)

model.summary()

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=['accuracy']
)

"""# Training model"""

with mlflow.start_run() as run:
  mlflow.set_tag("Machine Learning Engineer", "Mukhammad Fahevi Ali Rafsanjani")

  mlflow.log_param("train-data-path", "image-classification/images/images")
  mlflow.log_param("valid-data-path", "image-classification/validation/validation")
  model.fit(
      train_ds,
      validation_data = val_ds,
      epochs=5,
      callbacks=[mlflow.tensorflow.MlflowCallback()],
    )
  mlflow.tensorflow.log_model(
        model, "model", keras_model_kwargs={"save_format": "h5"}
    )

  # model_save_path = f"{mlflow_dir}/model.h5"
  # model.save(model_save_path)
loaded_model = mlflow.tensorflow.load_model(f"runs:/{run.info.run_id}/model")
print("Model loaded successfully!")

!pip install pyngrok -q

import subprocess
from pyngrok import ngrok, conf
import getpass

print("Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth")
conf.get_default().auth_token = getpass.getpass()

# Expose the MLflow UI on port 5000
port = 5000
public_url = ngrok.connect(port).public_url
print(f' * ngrok tunnel "{public_url}" -> "http://127.0.0.1:{port}"')

!mlflow ui --backend-store-uri "/content/drive/MyDrive/mlflow_image_classification" --port 5000 &

import shutil

# Define source folder and output zip file path
source_folder = "/content/drive/MyDrive/mlflow_logs"
zip_file = "/content/drive/MyDrive/mlflow_logs_backup.zip"

# Create a zip archive
shutil.make_archive(zip_file.replace(".zip", ""), 'zip', source_folder)

print(f"Zipped folder saved to: {zip_file}")

